# Natural-Language-Processing

## Gutenberg project
Using Pythonâ€™s NLTK library, we loaded 10 books of our choice from project
Gutenberg corpus (supported by NLTK).Then we created a dictionary from all
of them words that appear in each book and divided the texts into sentences and
tokens. After that we calculate frequencies of unigrams, bigrams and trigrams.
Finally we generated 10 sentences for each book using the bigrams and trigrams
